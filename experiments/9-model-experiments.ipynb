{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model experiments\n",
    "In this notebook we will try to write a couple of models to use for our experiments. Specifically, we will be implementing them so that they are `sklearn` compatible. Specifically we will be using two models to compare. Our end goal would be to actually have tools to plug the model in a `sklearn` pipeline and reliably measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# standard library\n",
    "import itertools\n",
    "import sys, os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from collections import OrderedDict\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "from dask import persist\n",
    "\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# skelearn\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# local imports\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "# this styling is purely my preference\n",
    "# less chartjunk\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'line.linewidth': 2.5})\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.context.set_options at 0x7fbdb6f79518>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.set_options(temporary_directory='/home/jovyan/work/partd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>sibling_pos</th>\n",
       "      <th>no_classes</th>\n",
       "      <th>id_len</th>\n",
       "      <th>class_len</th>\n",
       "      <th>no_children</th>\n",
       "      <th>text_len</th>\n",
       "      <th>descendant1_no_nodes</th>\n",
       "      <th>descendant1_no_children_avg</th>\n",
       "      <th>descendant1_id_len_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>ancestor5_tag_h3</th>\n",
       "      <th>ancestor5_tag_maxamineignore</th>\n",
       "      <th>ancestor5_tag_a</th>\n",
       "      <th>ancestor5_tag_ifcommentsaccepted</th>\n",
       "      <th>ancestor5_tag_noindex</th>\n",
       "      <th>ancestor5_tag_property</th>\n",
       "      <th>ancestor5_tag_iframe</th>\n",
       "      <th>ancestor5_tag_http:</th>\n",
       "      <th>ancestor5_tag_bodyonload</th>\n",
       "      <th>content_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  sibling_pos  no_classes  id_len  class_len  no_children  text_len  \\\n",
       "0      3           12           0       0          0            0         0   \n",
       "1      3            0           0       6          0            2        30   \n",
       "2      8            1           0       0          0            0         0   \n",
       "3      8           56           0       0          0            1         0   \n",
       "4      9            2           1       0          4            0       254   \n",
       "\n",
       "   descendant1_no_nodes  descendant1_no_children_avg  descendant1_id_len_avg  \\\n",
       "0                     0                          0.0                     0.0   \n",
       "1                     2                          1.0                     2.0   \n",
       "2                     0                          0.0                     0.0   \n",
       "3                     1                          1.0                     0.0   \n",
       "4                     0                          0.0                     0.0   \n",
       "\n",
       "       ...        ancestor5_tag_h3  ancestor5_tag_maxamineignore  \\\n",
       "0      ...                       0                             0   \n",
       "1      ...                       0                             0   \n",
       "2      ...                       0                             0   \n",
       "3      ...                       0                             0   \n",
       "4      ...                       0                             0   \n",
       "\n",
       "   ancestor5_tag_a  ancestor5_tag_ifcommentsaccepted  ancestor5_tag_noindex  \\\n",
       "0                0                                 0                      0   \n",
       "1                0                                 0                      0   \n",
       "2                0                                 0                      0   \n",
       "3                0                                 0                      0   \n",
       "4                0                                 0                      0   \n",
       "\n",
       "   ancestor5_tag_property  ancestor5_tag_iframe  ancestor5_tag_http:  \\\n",
       "0                       0                     0                    0   \n",
       "1                       0                     0                    0   \n",
       "2                       0                     0                    0   \n",
       "3                       0                     0                    0   \n",
       "4                       0                     0                    0   \n",
       "\n",
       "   ancestor5_tag_bodyonload  content_label  \n",
       "0                         0          False  \n",
       "1                         0          False  \n",
       "2                         0          False  \n",
       "3                         0          False  \n",
       "4                         0          False  \n",
       "\n",
       "[5 rows x 1327 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the features \n",
    "feat_ddf = dd.read_csv('../data/final/dragnet/dom-full-*.csv')\n",
    "feat_ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "In order to use our data for different model, we should normaize it first so that it's centerend in 0 and between -1 and 1. This way wewill ensure faster convergence for most gradeint descent-absed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler(sklearn.preprocessing.StandardScaler):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._reset()\n",
    "        to_persist = OrderedDict()\n",
    "\n",
    "        if self.with_mean:\n",
    "            mean_ = X.mean(0)\n",
    "            to_persist['mean_'] = mean_\n",
    "        if self.with_std:\n",
    "            to_persist['scale_'] = X.std(0)\n",
    "\n",
    "        to_persist['n_samples_seen_'] = len(X)\n",
    "        \n",
    "        values = persist(*to_persist.values())\n",
    "\n",
    "        for k, v in zip(to_persist, values):\n",
    "            setattr(self, k, v)\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y=None):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        if self.with_mean:\n",
    "            X -= self.mean_\n",
    "        if self.with_std:\n",
    "            X /= self.scale_\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        if self.with_std:\n",
    "            X *= self.scale_\n",
    "        if self.with_mean:\n",
    "            X += self.mean_\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(feat_ddf.drop(['url', 'path', 'content_label'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>sibling_pos</th>\n",
       "      <th>no_classes</th>\n",
       "      <th>id_len</th>\n",
       "      <th>class_len</th>\n",
       "      <th>no_children</th>\n",
       "      <th>text_len</th>\n",
       "      <th>descendant1_no_nodes</th>\n",
       "      <th>descendant1_no_children_avg</th>\n",
       "      <th>descendant1_id_len_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>ancestor5_tag_dt</th>\n",
       "      <th>ancestor5_tag_h3</th>\n",
       "      <th>ancestor5_tag_maxamineignore</th>\n",
       "      <th>ancestor5_tag_a</th>\n",
       "      <th>ancestor5_tag_ifcommentsaccepted</th>\n",
       "      <th>ancestor5_tag_noindex</th>\n",
       "      <th>ancestor5_tag_property</th>\n",
       "      <th>ancestor5_tag_iframe</th>\n",
       "      <th>ancestor5_tag_http:</th>\n",
       "      <th>ancestor5_tag_bodyonload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.665306</td>\n",
       "      <td>0.064887</td>\n",
       "      <td>-0.588170</td>\n",
       "      <td>-0.322564</td>\n",
       "      <td>-0.502271</td>\n",
       "      <td>-0.238585</td>\n",
       "      <td>-0.096867</td>\n",
       "      <td>-0.238585</td>\n",
       "      <td>-0.185236</td>\n",
       "      <td>-0.203909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006146</td>\n",
       "      <td>-0.002146</td>\n",
       "      <td>-0.018391</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.00096</td>\n",
       "      <td>-0.008745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.665306</td>\n",
       "      <td>-0.175504</td>\n",
       "      <td>-0.588170</td>\n",
       "      <td>0.587575</td>\n",
       "      <td>-0.502271</td>\n",
       "      <td>0.239191</td>\n",
       "      <td>-0.087393</td>\n",
       "      <td>0.239191</td>\n",
       "      <td>0.250009</td>\n",
       "      <td>0.289981</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006146</td>\n",
       "      <td>-0.002146</td>\n",
       "      <td>-0.018391</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.00096</td>\n",
       "      <td>-0.008745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.611792</td>\n",
       "      <td>-0.155472</td>\n",
       "      <td>-0.588170</td>\n",
       "      <td>-0.322564</td>\n",
       "      <td>-0.502271</td>\n",
       "      <td>-0.238585</td>\n",
       "      <td>-0.096867</td>\n",
       "      <td>-0.238585</td>\n",
       "      <td>-0.185236</td>\n",
       "      <td>-0.203909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006146</td>\n",
       "      <td>-0.002146</td>\n",
       "      <td>-0.018391</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.00096</td>\n",
       "      <td>-0.008745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.611792</td>\n",
       "      <td>0.946323</td>\n",
       "      <td>-0.588170</td>\n",
       "      <td>-0.322564</td>\n",
       "      <td>-0.502271</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>-0.096867</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.250009</td>\n",
       "      <td>-0.203909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006146</td>\n",
       "      <td>-0.002146</td>\n",
       "      <td>-0.018391</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.00096</td>\n",
       "      <td>-0.008745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.401089</td>\n",
       "      <td>-0.135439</td>\n",
       "      <td>0.492541</td>\n",
       "      <td>-0.322564</td>\n",
       "      <td>-0.146124</td>\n",
       "      <td>-0.238585</td>\n",
       "      <td>-0.016653</td>\n",
       "      <td>-0.238585</td>\n",
       "      <td>-0.185236</td>\n",
       "      <td>-0.203909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006146</td>\n",
       "      <td>-0.002146</td>\n",
       "      <td>-0.018391</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.00096</td>\n",
       "      <td>-0.008745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      depth  sibling_pos  no_classes    id_len  class_len  no_children  \\\n",
       "0 -1.665306     0.064887   -0.588170 -0.322564  -0.502271    -0.238585   \n",
       "1 -1.665306    -0.175504   -0.588170  0.587575  -0.502271     0.239191   \n",
       "2 -0.611792    -0.155472   -0.588170 -0.322564  -0.502271    -0.238585   \n",
       "3 -0.611792     0.946323   -0.588170 -0.322564  -0.502271     0.000303   \n",
       "4 -0.401089    -0.135439    0.492541 -0.322564  -0.146124    -0.238585   \n",
       "\n",
       "   text_len  descendant1_no_nodes  descendant1_no_children_avg  \\\n",
       "0 -0.096867             -0.238585                    -0.185236   \n",
       "1 -0.087393              0.239191                     0.250009   \n",
       "2 -0.096867             -0.238585                    -0.185236   \n",
       "3 -0.096867              0.000303                     0.250009   \n",
       "4 -0.016653             -0.238585                    -0.185236   \n",
       "\n",
       "   descendant1_id_len_avg            ...             ancestor5_tag_dt  \\\n",
       "0               -0.203909            ...                    -0.006146   \n",
       "1                0.289981            ...                    -0.006146   \n",
       "2               -0.203909            ...                    -0.006146   \n",
       "3               -0.203909            ...                    -0.006146   \n",
       "4               -0.203909            ...                    -0.006146   \n",
       "\n",
       "   ancestor5_tag_h3  ancestor5_tag_maxamineignore  ancestor5_tag_a  \\\n",
       "0         -0.002146                     -0.018391        -0.006439   \n",
       "1         -0.002146                     -0.018391        -0.006439   \n",
       "2         -0.002146                     -0.018391        -0.006439   \n",
       "3         -0.002146                     -0.018391        -0.006439   \n",
       "4         -0.002146                     -0.018391        -0.006439   \n",
       "\n",
       "   ancestor5_tag_ifcommentsaccepted  ancestor5_tag_noindex  \\\n",
       "0                         -0.004894              -0.001357   \n",
       "1                         -0.004894              -0.001357   \n",
       "2                         -0.004894              -0.001357   \n",
       "3                         -0.004894              -0.001357   \n",
       "4                         -0.004894              -0.001357   \n",
       "\n",
       "   ancestor5_tag_property  ancestor5_tag_iframe  ancestor5_tag_http:  \\\n",
       "0               -0.001357             -0.001357             -0.00096   \n",
       "1               -0.001357             -0.001357             -0.00096   \n",
       "2               -0.001357             -0.001357             -0.00096   \n",
       "3               -0.001357             -0.001357             -0.00096   \n",
       "4               -0.001357             -0.001357             -0.00096   \n",
       "\n",
       "   ancestor5_tag_bodyonload  \n",
       "0                 -0.008745  \n",
       "1                 -0.008745  \n",
       "2                 -0.008745  \n",
       "3                 -0.008745  \n",
       "4                 -0.008745  \n",
       "\n",
       "[5 rows x 1324 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_ddf = scaler.transform(feat_ddf.drop(['url', 'path', 'content_label'], axis=1))\n",
    "scaled_ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## da.learn\n",
    "We will try to use da.learn to actualyl fit an `sklearn` model that supports partial fitting. IF this is sucessful, we will use it to implement our wrapper/mixin so we can add it to any sklearn model(including the one we plan to implemnt in `tf` and us it in our pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using a stochastic gradient descent classifier for this test\n",
    "model = SGDClassifier()  \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<values, shape=(nan, 1324), dtype=float64, chunksize=(nan, 1324)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_ddf.values  # we will be apssing this to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.learn.fit(model, scaled_ddf.values, y=feat_ddf['content_label'].values, classes=[0, 1])  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a couple predictios with the distributed predict\n",
    "pred_ddf =  da.learn.predict(model, scaled_ddf.values)\n",
    "pred_arr = pred_ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_arr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have proof of it actually working without overflowing our memory, next thing to do is to try and implement it as a mixin or decorator for models so we can use them in `Pipeline` so they will accept `dask` dataframes and defer the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _BigPartialFitMixin(object):\n",
    "    \"\"\" Wraps a partial_fit enabled estimator for use with Dask arrays \"\"\"\n",
    "\n",
    "    _init_kwargs = []\n",
    "    _fit_kwargs = []\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        missing = set(self._init_kwargs) - set(kwargs)\n",
    "\n",
    "        if missing:\n",
    "            raise TypeError(\"{} requires the keyword arguments {}\".format(\n",
    "                type(self), missing)\n",
    "            )\n",
    "        for kwarg in self._init_kwargs:\n",
    "            setattr(self, kwarg, kwargs.pop(kwarg))\n",
    "        super(_BigPartialFitMixin, self).__init__(**kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_param_names(cls):\n",
    "        # Evil hack to make sure repr, get_params work\n",
    "        # We could also try rewriting __init__ once the class is created\n",
    "        bases = cls.mro()\n",
    "        # walk bases until you hit an sklearn class.\n",
    "        for base in bases:\n",
    "            if base.__module__.startswith(\"sklearn\"):\n",
    "                break\n",
    "\n",
    "        # merge the inits\n",
    "        my_init = cls._init_kwargs\n",
    "        their_init = base._get_param_names()\n",
    "        return my_init + their_init\n",
    "\n",
    "    def fit(self, X, y=None, get=None):\n",
    "        if get is None:\n",
    "            get = dask.threaded.get\n",
    "\n",
    "        fit_kwargs = {k: getattr(self, k) for k in self._fit_kwargs}\n",
    "        result = da.learn.fit(self, X, y, get=get, **fit_kwargs)\n",
    "\n",
    "        # Copy the learned attributes over to self\n",
    "        # It should go without saying that this is *not* threadsafe\n",
    "        attrs = {k: v for k, v in vars(result).items() if k.endswith('_')}\n",
    "        for k, v in attrs.items():\n",
    "            setattr(self, k, v)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, dtype=None):\n",
    "        predict = super(_BigPartialFitMixin, self).predict\n",
    "        if dtype is None:\n",
    "            dtype = self._get_predict_dtype(X)\n",
    "        return X.map_blocks(predict, dtype=dtype, drop_axis=1)\n",
    "\n",
    "    def _get_predict_dtype(self, X):\n",
    "        xx = np.zeros((1, X.shape[1]), dtype=X.dtype)\n",
    "        return super(_BigPartialFitMixin, self).predict(xx).dtype\n",
    "    \n",
    "class DaskSGDClassifier(_BigPartialFitMixin, SGDClassifier):\n",
    "    _init_kwargs = ['classes']\n",
    "    _fit_kwargs = ['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DaskSGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "         classes=[0, 1], epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "         l1_ratio=0.15, learning_rate='optimal', loss='hinge', n_iter=5,\n",
       "         n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "         shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DaskSGDClassifier(classes=[0, 1])\n",
    "model.fit(scaled_ddf.values, y=feat_ddf['content_label'].values)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_ddf.values).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In the meantime the package `dask-ml` has been realeased which pretty much implements these desired features in a far better tested manner. We will be exploring that package in another notebook, where we will also try to implement our `sklearn`-compatible and even `dask-ml` compatible `tensorflow` estmator to use as our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
